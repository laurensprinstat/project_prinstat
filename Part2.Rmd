---
title: "R Notebook"
output: html_notebook
---



```{r}
library(plyr)
library(coin)

```


```{r}
# Read in data
data <- read.table("bptrial.txt", header=TRUE, sep=",", dec=".")
original <- data
# Set column names
colnames(data) <- c("treatment", "sex", "weight", "age",
                    "comp", "dbpdif", "dbp3", "dbp2", "dbp1")
# Add column dbp_end for the 5th measurement at the end of the experiment
data$dbp_end <- data$dbp3 + data$dbpdif
# Mean dbp during the run-in period
data$dbp_mean <- round((data$dbp1 + data$dbp2 + data$dbp3) / 3, 1)
# Raw data subset
data_raw <- data
# Treatment group as factor
data$treatment <- as.factor(mapvalues(
  data$treatment,
  from=c(1, 2, 3),
  to=c("Treatment 1", "Placebo", "Treatment 3")
))
# Gender as factor
data$sex <- as.factor(mapvalues(data$sex, from=c(0, 1), to=c("Female", "Male")))
# 80% adherence rule
data <- data[data$comp >= 0.8,]
##TS: don't we remove the patient with a blood pressure of 66?
data = data[data$dbp3 != 66,]
# Subset of treatment 1 and the placebo
data12 <- data[data$treatment != "Treatment 3",]
levels(data12$treatment) <- c("Treatment 1", "Placebo", NA)
```
```{r}
##################
#Question 1 (TS) #
##################
n1 <- summary(data$treatment)[[1]]
n2 <- summary(data$treatment)[[2]]

#Simulating the dbpdif data
qqnorm(data$dbpdif[data$treatment == "Treatment 1"]) ; qqline(data$dbpdif[data$treatment == "Treatment 1"])
#Skewed to the left?
qqnorm(data$dbpdif[data$treatment == "Placebo"]) ; qqline(data$dbpdif[data$treatment == "Placebo"])
#Short tail on the right?
var.test(data$dbpdif[data$treatment == "Treatment 1"], data$dbpdif[data$treatment == "Placebo"])
#Although just not significant, the ratio of the variances seems to deviate from 1. I think it would be safer to assume that the variances are not equal.

mu_dif1 <- mean(data$dbpdif[data$treatment == "Treatment 1"])
mu_dif2 <- mean(data$dbpdif[data$treatment == "Placebo"])
sd_dif1 <- sd(data$dbpdif[data$treatment == "Treatment 1"])
sd_dif2 <- sd(data$dbpdif[data$treatment == "Placebo"])

rdif1 <- rnorm(n1, mu_dif1, sd_dif1)
rdif2 <- rnorm(n2, mu_dif2, sd_dif2)
qqnorm(rdif1) ; qqline(rdif1)
qqnorm(rdif2) ; qqline(rdif2)
##QQplots from data generated randomly from normal distributions show similar deviations as the QQplots of the data

#Simulating the dbp_end data
qqnorm(data$dbp_end[data$treatment == "Treatment 1"]) ; qqline(data$dbp_end[data$treatment == "Treatment 1"])
#1 outlier to the left?
qqnorm(data$dbp_end[data$treatment == "Placebo"]) ; qqline(data$dbp_end[data$treatment == "Placebo"])
#Short tail on the left?
#The dbp_end seems to show fewer deviations from normality than dbpdif

mu_end1 <- mean(data$dbp_end[data$treatment == "Treatment 1"])
mu_end2 <- mean(data$dbp_end[data$treatment == "Placebo"])
sd_end1 <- sd(data$dbp_end[data$treatment == "Treatment 1"])
sd_end2 <- sd(data$dbp_end[data$treatment == "Placebo"])

rend1 <- rnorm(n1, mu_end1, sd_end1)
rend2 <- rnorm(n2, mu_end2, sd_end2)
qqnorm(rend1) ; qqline(rend1)
qqnorm(rend2) ; qqline(rend2)
##QQplots from data generated randomly from normal distributions show similar deviations as the QQplots of the data

##Parametric simulation: 10000 simulations for each of 40 differences in means, both for dbpdif and dbp_end. These are plotted together for comparison
pwr_dif <- vector(,41)
set.seed(2018)
for(y in 0:40){
  x <- 0.025 * y
  pdif <- vector(, 10000)
  for(i in 1:10000) {
    mu_dif1.2 <- mu_dif1 + (abs(mu_dif1) - abs(mu_dif2)) * x
    rdif1 <- rnorm(n1, mu_dif1.2, sd_dif1)
    rdif2 <- rnorm(n2, mu_dif2, sd_dif2)
    tdif <- t.test(rdif1, rdif2, alternative = "less", mu = 0, paired = F, var.equal = F)
    pdif[i] <- tdif$p.value
  }
  pwr_dif[y+1] <-mean(pdif < 0.05)
}

pwr_end <- vector(,41)
set.seed(2019)
for(y in 0:40){
  x <- 0.025 * y
  pend <- vector(, 10000)
  for(i in 1:10000) {
    mu_end1.2 <- mu_end1 + (mu_end2 - mu_end1) * x
    rend1 <- rnorm(n1, mu_end1.2, sd_end1)
    rend2 <- rnorm(n2, mu_end2, sd_end2)
    tend <- t.test(rend1, rend2, alternative = "less", mu = 0, paired = F, var.equal = F)
    pend[i] <- tend$p.value
  }
  pwr_end[y+1] <-mean(pend < 0.05)
}

#Plotting both power simulations in the same graph
plot(pwr_dif, type = "n", xaxt = "n", xlab = "Difference in means (% observed difference)", 
     yaxt = "n", ylab = "Power (%)", main = "Comparative power") ; 
lines(rev(pwr_dif), lty = 1, col = "blue") ; lines(rev(pwr_end), pch = 1, lty = 2, col = "red")
axis(side = 1, at = seq(from = 0, to = 40, by = 4), labels = seq(from = 0, to = 100, by = 10))
axis(side = 2, at = seq(from = 0, to = 1, by = 0.2), labels = seq(from = 0, to = 100, by = 20))
legend(33.77, 1.036, legend = c("dbp_dif", "dbp_end"),
       col = c("blue", "red"), lty=1:2, cex=1.2)
```

##################
#Question 2 (TS) #
##################
```{r}
##Analytical approach to the power of the t-test
alpha <- 0.05
n <- n1 + n2
#Alpha is not divided by 2, as we test one-sided
t.alpha <- qt(1-alpha, df = n - 2)

#With dbpdif, where the difference between the groups is 42.5% of the observed difference
delta_dif <- -(mu_dif1 - mu_dif2) * 0.425
lambda_dif <- delta_dif /  sqrt(var(data$dbpdif[data$treatment == "Treatment 1"])/n1 + 
                                      var(data$dbpdif[data$treatment == "Placebo"])/n2)
1 - pt(t.alpha, df = n - 2, ncp = lambda_dif)

#With dbp_end, where the difference between the groups is 42,5% of the observed difference
delta_end <- -(mu_end1 - mu_end2) * 0.425
lambda_end <- delta_end /  sqrt(var(data$dbp_end[data$treatment == "Treatment 1"])/n1 + 
                                      var(data$dbp_end[data$treatment == "Placebo"])/n2)
1 - pt(t.alpha, df = n - 2, ncp = lambda_end)

#Non-parametric alternative: The l (lambda) is much too large, this doesn't work
l_dif.2 <- sqrt((12 * n1 * n2) / (n + 1)) * delta_dif.2
1 - pt(t.alpha, df = n - 2, ncp = l_dif.2)
```

###################
# Question 3 (LS) #
###################

```{r}
n <- 1000000
power <- vector(, n)
type1 <- vector(, n)
set.seed(1991)
for(i in 1:n){
  r_placebo <- rnorm(n=n_placebo, mean=mean_placebo, sd=sd_placebo)
  r_treat <- rnorm(n=n_treatment, mean=mean_treatment, sd=sd_treatment)
  r_placebo_0 <- rnorm(n=n_placebo, mean=0, sd=sd_placebo)
  r_treat_0 <- rnorm(n=n_treatment, mean=0, sd=sd_treatment)
  # One sided pooled t-test
  test <- t.test(r_treat, r_placebo, alternative="less", var.equal=FALSE)
  test_0 <- t.test(r_treat_0, r_placebo_0, alternative="greater", var.equal=FALSE)
  power[i] <- test$p.value
  type1[i] <- test_0$p.value
}
# Power
mean(power < 0.05)
# Type 1
mean(type1 < 0.05)
```

[1] 0.999900
Approx power approaching 100% or >99.9%

[1] 0.050319
Type 1 error rate of approx 5%?


